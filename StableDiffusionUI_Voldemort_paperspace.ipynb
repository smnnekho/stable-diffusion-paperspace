{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Installation and Setup\n",
    "\n",
    "You must reinstall everything each time you restart the machine. If already downloaded, dependencies will be auto-updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free tier\n",
    "# symlink_to_notebooks = True                          # Enables the creation of symlinks back to /notebooks/\n",
    "# model_storage_dir = '/tmp/stable-diffusion/models'   # Where the models will be downloaded to.\n",
    "# repo_storage_dir = '/notebooks'                      # Where the repository will be downloaded to.\n",
    "\n",
    "# Paid Tier\n",
    "# symlink_to_notebooks = False\n",
    "# model_storage_dir = '/storage/models'\n",
    "# repo_storage_dir = '/notebooks'\n",
    "\n",
    "\n",
    "# Other optional settings\n",
    "# You don't have to change these if you don't want to\n",
    "\n",
    "activate_xformers = True                              # Enables the xformers optimizations using pre-built wheels.\n",
    "                                                       # Setting to True will automatically set up your environment/machine for xformers. \n",
    "\n",
    "link_novelai_anime_vae = False                         # Enables the linking of animevae.pt to each of the NovelAI models.\n",
    "                                                       # Set to True if you've downloaded both the NovelAI models and hypernetworks.\n",
    "\n",
    "download_scripts = True                               # Download custom scripts? Only reason why you would leave it disabled is because it may\n",
    "                                                       # take a while to complete.\n",
    "\n",
    "activate_deepdanbooru = False                          # Enable and install DeepDanbooru -> https://github.com/KichangKim/DeepDanbooru\n",
    "\n",
    "activate_medvram = False                                # Enable medvram option.\n",
    "                                                       # These are model optimizations which will reduce VRAM usage at the expense of some speed.\n",
    "                                                       # Set to False if you have a lot of VRAM.\n",
    "\n",
    "disable_pickle_check = True                           # Disable the automatic check for unexpected data in model files.\n",
    "                                                       # Leave this set to False unless you have a reason to disable the check.\n",
    "\n",
    "gradio_port = False                                    # Launch Gradio on a specific port. Set to False to let Gradio choose a port.\n",
    "                                                       # This disables online Gradio app mode and you will only be able to access it on your local network.\n",
    "\n",
    "gradio_auth = False                                    # Enable gradio_auth and insecure-extension-access option.\n",
    "                                                       # Set to \"me:password\" to enable.\n",
    "\n",
    "search_paperspace_datasets = True                      # Enable searching for checkpoints in /datasets to link to the webui\n",
    "\n",
    "ui_theme = None                                        # Set the WEB UI theme. Values can be None (default) or 'dark'.\n",
    "\n",
    "insecure_extension_access = True                      # Force enable extensions without a password.\n",
    "                                                       # If you don't set a password, anyone can install and run arbitrary code on your machine!\n",
    "                                                       # Instead, use gradio_auth which will automatically enable extensions when set.\n",
    "\n",
    "\n",
    "# ===================================================================================================\n",
    "# Save variables to Jupiter's temp storage so we can access it even if the kernel restarts.\n",
    "%store symlink_to_notebooks model_storage_dir repo_storage_dir activate_xformers link_novelai_anime_vae download_scripts activate_deepdanbooru activate_medvram disable_pickle_check gradio_port gradio_auth search_paperspace_datasets ui_theme insecure_extension_access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clone the WebUI repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBbcB4vwj_jm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# You'll see this little code block at the beginning of every cell. It makes sure you have ran the first block that defines your settings.\n",
    "try:\n",
    "    %store -r symlink_to_notebooks model_storage_dir repo_storage_dir\n",
    "    test = [symlink_to_notebooks, model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "%cd /notebooks/\n",
    "\n",
    "def delete_broken_symlinks(path):\n",
    "    # make sure to pass this function a path without a trailing slash\n",
    "    for file in os.listdir(path):\n",
    "        if os.path.islink(f'{path}/{file}') and not os.path.exists(os.readlink(f'{path}/{file}')):\n",
    "            print(f'Symlink broken, removing: {file}')\n",
    "            os.unlink(f'{path}/{file}')\n",
    "\n",
    "def update_repo_if_not_exists(path, repo_clone_url, pre=None):\n",
    "    if pre is not None:\n",
    "        pre()    \n",
    "    if not os.path.exists(path):\n",
    "        !git clone \"{repo_clone_url}\" \"{path}\"\n",
    "    else:\n",
    "        print(f'{repo_clone_url.split(\"/\")[-1]} already downloaded, updating...')\n",
    "        !cd \"{path}\" && git pull # no % so we don't interfere with the main process\n",
    "\n",
    "def init_free():\n",
    "    if (symlink_to_notebooks and repo_storage_dir != '/notebooks'):\n",
    "        delete_broken_symlinks('/notebooks/') # remove broken symlinks since it might have been installed in a non-persistent directory\n",
    "        if not os.path.exists(repo_storage_dir):\n",
    "            !mkdir -p \"{repo_storage_dir}\"\n",
    "            !ln -s \"{repo_storage_dir}\" /notebooks/\n",
    "            !ls -la /notebooks/stable-diffusion\n",
    "update_repo_if_not_exists(f'{repo_storage_dir}/stable-diffusion-webui', 'https://github.com/AUTOMATIC1111/stable-diffusion-webui', init_free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C68TUpkq0nj_",
    "tags": []
   },
   "source": [
    "## Install requirements and download repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SaAJk33ppFw1",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r symlink_to_notebooks model_storage_dir repo_storage_dir activate_xformers download_scripts activate_deepdanbooru\n",
    "    test = [symlink_to_notebooks, model_storage_dir, repo_storage_dir, activate_xformers, download_scripts, activate_deepdanbooru]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "%cd \"{repo_storage_dir}/stable-diffusion-webui\"\n",
    "\n",
    "!pip install --upgrade pip\n",
    "\n",
    "import os\n",
    "\n",
    "# Import launch.py which will automatically run the install script but not launch the WebUI.\n",
    "# They require a few specific external git repo commits so we have to do it their way. \n",
    "import launch\n",
    "launch.prepare_environment()\n",
    "\n",
    "# The installer isn't installing deepdanbooru right now so we'll do it manually\n",
    "if activate_deepdanbooru:\n",
    "    !pip install \"git+https://github.com/KichangKim/DeepDanbooru.git@edf73df4cdaeea2cf00e9ac08bd8a9026b7a7b26#egg=deepdanbooru[tensorflow]\" # tensorflow==2.10.0 tensorflow-io==0.27.0 flatbuffers==1.12\n",
    "\n",
    "# latent-diffusion is a requirement but launch.py isn't downloading it so we'll do it manually.\n",
    "if not os.path.exists(f'{repo_storage_dir}/stable-diffusion-webui/repositories/latent-diffusion'):\n",
    "    !git clone https://github.com/crowsonkb/k-diffusion.git \"{repo_storage_dir}/stable-diffusion-webui/repositories/k-diffusion\"\n",
    "    !git clone https://github.com/Hafiidz/latent-diffusion.git \"{repo_storage_dir}/stable-diffusion-webui/repositories/latent-diffusion\"\n",
    "\n",
    "# For things in this notebook\n",
    "!pip install requests\n",
    "!pip install gdown\n",
    "\n",
    "# Download popular custom scripts. This is basically remote code execution so be careful.\n",
    "# See https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts\n",
    "if download_scripts:\n",
    "    import shutil\n",
    "    import requests\n",
    "    !pip install moviepy==1.0.3\n",
    "    !apt update\n",
    "    !apt install -y potrace python3-tk\n",
    "\n",
    "    def download_file_dir(url, output_dir):\n",
    "        # output_dir must have a trailing slash\n",
    "        local_filename = url.split('/')[-1]\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(f'{output_dir}{local_filename}', 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        return local_filename\n",
    "    def do_script_download(scripts_list, domain, path):\n",
    "        for item in scripts_list:\n",
    "            download_file_dir(f'https://{domain}/{item}', path)\n",
    "            print(f'{item.split(\"/\")[-1]} downloaded...')\n",
    "\n",
    "    do_script_download([\n",
    "        'GRMrGecko/stable-diffusion-webui-automatic/advanced_matrix/scripts/advanced_prompt_matrix.py',\n",
    "        'dfaker/stable-diffusion-webui-cv2-external-masking-script/main/external_masking.py',\n",
    "        'memes-forever/Stable-diffusion-webui-video/main/videos.py',\n",
    "        'yownas/seed_travel/main/scripts/seed_travel.py',\n",
    "        'Animator-Anon/Animator/main/animation.py',\n",
    "        'Filarius/stable-diffusion-webui/master/scripts/vid2vid.py',\n",
    "        'GeorgLegato/Txt2Vectorgraphics/main/txt2vectorgfx.py',\n",
    "        'yownas/shift-attention/main/scripts/shift_attention.py',\n",
    "        'DiceOwl/StableDiffusionStuff/main/loopback_superimpose.py',\n",
    "        'Engineer-of-Stuff/stable-diffusion-paperspace/main/lfs/save_steps.py',\n",
    "        'Pfaeff/sd-web-ui-scripts/main/moisaic.py'\n",
    "    ], 'raw.githubusercontent.com', f'{repo_storage_dir}/stable-diffusion-webui/scripts/')\n",
    "\n",
    "    do_script_download([\n",
    "        'dfaker/f88aa62e3a14b559fe4e5f6b345db664/raw/791dabfa0ab26399aa2635bcbc1cf6267aa4ffc2/alternate_sampler_noise_schedules.py',\n",
    "        'camenduru/9ec5f8141db9902e375967e93250860f/raw/c1a03eb447548adbef1858c0e69d3567a390d2f4/run_n_times.py'\n",
    "    ], 'gist.githubusercontent.com', f'{repo_storage_dir}/stable-diffusion-webui/scripts/')\n",
    "\n",
    "    # Download and set up txt2img2img\n",
    "    update_repo_if_not_exists(f'{repo_storage_dir}/stable-diffusion-webui/txt2img2img_root', 'https://github.com/ThereforeGames/txt2img2img.git')\n",
    "    !cp -r \"{repo_storage_dir}/stable-diffusion-webui/txt2img2img_root/scripts\" \"{repo_storage_dir}/stable-diffusion-webui\"\n",
    "    !cp -r \"{repo_storage_dir}/stable-diffusion-webui/txt2img2img_root/txt2img2img\" \"{repo_storage_dir}/stable-diffusion-webui\"\n",
    "    !cp -r \"{repo_storage_dir}/stable-diffusion-webui/txt2img2img_root/venv\" \"{repo_storage_dir}/stable-diffusion-webui\"\n",
    "\n",
    "    # Download and set up txt2mask\n",
    "    update_repo_if_not_exists(f'{repo_storage_dir}/stable-diffusion-webui/txt2mask', 'https://github.com/ThereforeGames/txt2mask.git')\n",
    "    !echo \"Copying txt2mask...\"\n",
    "    !cp -r \"{repo_storage_dir}/stable-diffusion-webui/txt2mask/repositories/clipseg\" \"{repo_storage_dir}/stable-diffusion-webui/repositories\"\n",
    "    !cp -r \"{repo_storage_dir}/stable-diffusion-webui/txt2mask/scripts/\" \"{repo_storage_dir}/stable-diffusion-webui/\"\n",
    "\n",
    "    # Install the dynamic-prompts/wildcard script\n",
    "    # !git clone https://github.com/adieyal/sd-dynamic-prompting/ extensions/dynamic-prompts\n",
    "\n",
    "if activate_xformers:\n",
    "    print('Installing xformers...')\n",
    "    import subprocess\n",
    "    def download_release(url):\n",
    "        binary = 'xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl' # have to save the binary as a specific name that pip likes\n",
    "        tmp_dir = subprocess.check_output(['mktemp', '-d']).decode('ascii').strip('\\n')\n",
    "        !wget \"{url}\" -O \"{tmp_dir}/{binary}\"\n",
    "        return os.path.join(tmp_dir, binary)\n",
    "\n",
    "    # Set up pip packages\n",
    "    !pip uninstall -y torch  torchvision torchaudio # Remove existing pytorch install.\n",
    "    !pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113 # Install pytorch for cuda 11.3\n",
    "    s = subprocess.getoutput('nvidia-smi')\n",
    "    if 'A4000' in s:\n",
    "        xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A4000-Oct-28-2022/a4000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "    elif 'A5000' in s:\n",
    "        xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A5000-Nov-1-2022/a5000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "    elif 'A6000' in s:\n",
    "        xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A6000-Nov-1-2022/a6000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "    elif 'P5000' in s:\n",
    "        xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/P5000-Nov-1-2022/p5000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "    elif 'RTX 4000' in s:\n",
    "        xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/RTX-4000-Nov-1-2022/rtx4000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "    elif 'RTX 5000' in s:\n",
    "        xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/RTX-5000-Nov-1-2022/rtx5000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "    elif 'A100' in s:\n",
    "        xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A100-Nov-1-2022/a100-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "    elif 'M4000' in s:\n",
    "        print('xformers for M4000 hasn\\'t been built yet.')\n",
    "        # xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A100-Nov-1-2022/a100-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "    else:\n",
    "        print('GPU not matched to xformers binary so a one-size-fits-all binary was installed. If you have any issues, please build xformers using the Tools block below.')\n",
    "        xformers_whl = download_release('https://raw.githubusercontent.com/Cyberes/xformers-compiled/main/various/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl')\n",
    "    !pip install --force-reinstall \"{xformers_whl}\"\n",
    "\n",
    "# Make sure your models storage directory exists\n",
    "!mkdir -p \"{model_storage_dir}/hypernetworks\"\n",
    "!mkdir -p \"{model_storage_dir}/vae\"\n",
    "!mkdir -p \"{repo_storage_dir}/stable-diffusion-webui/models/hypernetworks\"\n",
    "\n",
    "# Link the output folders to /notebooks/outputs\n",
    "!mkdir -p \"{repo_storage_dir}/stable-diffusion-webui/log/images\"\n",
    "!mkdir -p \"{repo_storage_dir}/stable-diffusion-webui/outputs\"\n",
    "!ln -s \"{repo_storage_dir}/stable-diffusion-webui/outputs\" /notebooks/\n",
    "!ln -s \"{repo_storage_dir}/stable-diffusion-webui/log\" \"{repo_storage_dir}/stable-diffusion-webui/outputs\"\n",
    "\n",
    "# Link /storage/ to /notebooks/\n",
    "!ln -s /storage/ /notebooks/\n",
    "\n",
    "!echo -e \"\\n===================================\\nDone! If you're seeing this the process has exited successfully.\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean up and restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir\n",
    "    test = [model_storage_dir, repo_storage_dir]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "# Get some storage back\n",
    "!pip cache purge\n",
    "!cd \"{model_storage_dir}\" && rm *.aria2\n",
    "!apt remove --purge -y aria2 p7zip-full\n",
    "!apt autoremove --purge -y\n",
    "!apt clean\n",
    "\n",
    "# Restart the kernel\n",
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link the models directory\n",
    "\n",
    "Create symlinks. The file will be stored in the models storage directory and linked to where the WebUI expects the files to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir link_novelai_anime_vae search_paperspace_datasets\n",
    "    test = [model_storage_dir, repo_storage_dir, link_novelai_anime_vae, search_paperspace_datasets]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import re\n",
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "if not os.path.isdir(model_storage_dir):\n",
    "    print('Your model storage directory does not exist:', model_storage_dir)\n",
    "    sys.exit(1)\n",
    "\n",
    "webui_model_path = Path(repo_storage_dir, 'stable-diffusion-webui/models')\n",
    "webui_sd_models = Path(webui_model_path, 'Stable-diffusion')\n",
    "webui_hypernetworks = Path(webui_model_path, 'hypernetworks')\n",
    "webui_vaes = Path(webui_model_path, 'VAE')\n",
    "\n",
    "def delete_broken_symlinks(dir):\n",
    "    deleted = False\n",
    "    for file in os.listdir(dir):\n",
    "        path = f'{dir}/{file}'\n",
    "        if os.path.islink(path) and not os.path.exists(os.readlink(path)):\n",
    "            print(f'Symlink broken, removing: {file}')\n",
    "            os.unlink(path)\n",
    "            deleted = True\n",
    "    if deleted:\n",
    "        print('')\n",
    "        \n",
    "def create_symlink(source, dest):\n",
    "    if os.path.isdir(dest):\n",
    "        dest = Path(dest, os.path.basename(source))\n",
    "    if not os.path.exists(dest):\n",
    "        !ln -s \"{source}\" \"{dest}\"\n",
    "    print(source, '->', Path(dest).absolute())\n",
    "\n",
    "# Check for broken symlinks and remove them\n",
    "print('Removing broken symlinks...')\n",
    "delete_broken_symlinks(webui_sd_models)\n",
    "delete_broken_symlinks(webui_hypernetworks)\n",
    "delete_broken_symlinks(webui_vaes)\n",
    "\n",
    "# Link .ckpt files (recursive)\n",
    "print('\\nLinking .ckpt files...')\n",
    "for file in glob.glob(f'{model_storage_dir}/**/*.ckpt', recursive=True):\n",
    "    if not Path(file).parent.parts[-1] in ['hypernetworks', 'vae'] :\n",
    "        if not os.path.exists(file):\n",
    "            print('New model:', os.path.basename(file))\n",
    "        create_symlink(file, webui_sd_models)\n",
    "\n",
    "# Link config yaml files\n",
    "print('\\nLinking config .yaml files...')\n",
    "for file in glob.glob(f'{model_storage_dir}/**/*.yaml', recursive=True):\n",
    "    create_symlink(file, webui_sd_models)\n",
    "\n",
    "# Link hypernetworks\n",
    "print('\\nLinking hypernetworks...')\n",
    "source_hypernetworks = Path(model_storage_dir, 'hypernetworks')\n",
    "if os.path.isdir(source_hypernetworks):\n",
    "    for file in os.listdir(source_hypernetworks):\n",
    "        create_symlink(Path(source_hypernetworks, file), webui_hypernetworks)\n",
    "else:\n",
    "    print('Hypernetwork storage directory not found:', source_hypernetworks)\n",
    "\n",
    "# Link VAEs\n",
    "print('\\nLinking VAEs...')\n",
    "source_vaes = Path(model_storage_dir, 'vae')\n",
    "if os.path.isdir(source_vaes):\n",
    "    for file in os.listdir(source_vaes):\n",
    "        create_symlink(Path(source_vaes, file), webui_vaes)\n",
    "else:\n",
    "    print('VAE storage directory not found:', source_vaes)\n",
    "\n",
    "# Link the NovelAI files for each of the NovelAI models\n",
    "print('\\nLinking NovelAI files for each of the NovelAI models...')\n",
    "for model in glob.glob(f'{model_storage_dir}/novelai-*.ckpt'):\n",
    "    yaml = model.replace('.ckpt', '.yaml')\n",
    "    if os.path.exists(yaml):\n",
    "        # if not os.path.exists(yaml):\n",
    "        print(f'New NovelAI model config: {yaml}')\n",
    "        create_symlink(yaml, webui_sd_models)\n",
    "\n",
    "if link_novelai_anime_vae:\n",
    "    print('\\nLinking NovelAI anime VAE...')\n",
    "    for model in glob.glob('novelai-*.ckpt'):\n",
    "        if os.path.exists(Path(model_storage_dir, 'hypernetworks/animevae.pt')):\n",
    "            vae = model.replace('.ckpt', '.vae.pt')\n",
    "            if not os.path.exists(webui_vaes):\n",
    "                print(f'Linking NovelAI {vae} and {model}')\n",
    "            create_symlink(Path(model_storage_dir, 'hypernetworks/animevae.pt'), webui_vaes)\n",
    "        else:\n",
    "            print(f'{model_storage_dir}/hypernetworks/animevae.pt NOT FOUND')\n",
    "            \n",
    "\n",
    "if search_paperspace_datasets:\n",
    "    if os.path.isdir('/datasets'):\n",
    "        print('\\nSearching /datasets')\n",
    "        for file in glob.glob(f'/datasets/**/*.ckpt', recursive=True):\n",
    "            create_symlink(file, webui_sd_models)\n",
    "        for file in glob.glob(f'/datasets/**/*.yaml', recursive=True):\n",
    "            create_symlink(file, webui_sd_models)\n",
    "    else:\n",
    "        print('\\nNo datasets mounted!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xt8lbdmC04ox"
   },
   "source": [
    "# Launch the WebUI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Run this block to launch the WebUI. You will get a link to nnn.gradio.app, that's your WebUI. Follow it.\n",
    "\n",
    "See [shared.py](https://github.com/AUTOMATIC1111/stable-diffusion-webui/blob/master/modules/shared.py#L22) to view the code for the launch args. There's a lot of good info in there about exactly what the args do. If you aren't a programmer, [here's the wiki](https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Command-Line-Arguments-and-Settings).\n",
    "\n",
    "#### Troubleshooting\n",
    "- If you have any issues, try restarting the kernel.\n",
    "- `EOFError: Ran out of input` probably means you ran out of storage space and the model `.ckpt` file wasn't downloaded completely. Try cleaning up your files. There are some helpful scripts in the Tools section below.\n",
    "- `The file may be malicious, so the program is not going to read it` means the program encountered unexpected data in the model file (the technical term is \"pickle\"). Merging models can cause this. You can disable this feature by setting `disable_pickle_check` to True in the settings block.\n",
    "- Try updating your notebook using the block in the Tools section below.\n",
    "- If you're still having issues, delete `stable-diffusion-webui` and reinstall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R-xAdMA5wxXd",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    %store -r model_storage_dir repo_storage_dir activate_xformers activate_deepdanbooru activate_medvram disable_pickle_check gradio_port gradio_auth ui_theme insecure_extension_access\n",
    "    test = [model_storage_dir, repo_storage_dir, activate_xformers, activate_deepdanbooru, activate_medvram, disable_pickle_check, gradio_port, gradio_auth, ui_theme, insecure_extension_access]\n",
    "except NameError as e:\n",
    "    print(\"There is an issue with your variables.\")\n",
    "    print(\"Please go back to the first block and make sure your settings are correct, then run the cell.\")\n",
    "    print('Error:', e)\n",
    "    import sys\n",
    "    sys.exit(1)\n",
    "\n",
    "%cd \"{repo_storage_dir}/stable-diffusion-webui\"\n",
    "\n",
    "# Code to set the options you want as defined in the very first block\n",
    "x_arg = '--xformers' if activate_xformers else ''\n",
    "dd_arg = '--deepdanbooru' if activate_deepdanbooru else ''\n",
    "mvram_arg = '--medvram' if activate_medvram else ''\n",
    "pickled = '--disable-safe-unpickle' if disable_pickle_check else ''\n",
    "port = f'--port {gradio_port}' if gradio_port else '--share'\n",
    "auth = f'--gradio-auth {gradio_auth} --enable-insecure-extension-access' if gradio_auth else ''\n",
    "theme = f'--theme {ui_theme}' if ui_theme else ''\n",
    "insecure_extension_access = '--enable-insecure-extension-access' if insecure_extension_access else ''\n",
    "\n",
    "# Launch args go below:\n",
    "!python webui.py {x_arg} {dd_arg} {mvram_arg} {pickled} {port} {auth} {theme} --gradio-debug"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
