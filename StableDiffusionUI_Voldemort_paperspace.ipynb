{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Installation and Setup\n",
    "\n",
    "You must reinstall everything each time you restart the machine. If already downloaded, dependencies will be auto-updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "symlink_to_notebooks = False\n",
    "model_storage_dir = '/storage/models'\n",
    "repo_storage_dir = '/notebooks'\n",
    "\n",
    "activate_xformers = False                              # Enables the xformers optimizations using pre-built wheels.\n",
    "                                                       # Setting to True will automatically set up your environment/machine for xformers. \n",
    "link_novelai_anime_vae = False                         # Enables the linking of animevae.pt to each of the NovelAI models.\n",
    "                                                       # Set to True if you've downloaded both the NovelAI models and hypernetworks.\n",
    "download_scripts = True                               # Download custom scripts? Only reason why you would leave it disabled is because it may\n",
    "                                                       # take a while to complete.\n",
    "activate_deepdanbooru = False                          # Enable and install DeepDanbooru -> https://github.com/KichangKim/DeepDanbooru\n",
    "activate_medvram = False                                # Enable medvram option.\n",
    "                                                       # These are model optimizations which will reduce VRAM usage at the expense of some speed.\n",
    "                                                       # Set to False if you have a lot of VRAM.\n",
    "disable_pickle_check = True                           # Disable the automatic check for unexpected data in model files.\n",
    "                                                       # Leave this set to False unless you have a reason to disable the check.\n",
    "gradio_port = False                                    # Launch Gradio on a specific port. Set to False to let Gradio choose a port.\n",
    "                                                       # This disables online Gradio app mode and you will only be able to access it on your local network.\n",
    "gradio_auth = False                                    # Enable gradio_auth and insecure-extension-access option.\n",
    "                                                       # Set to \"me:password\" to let Gradio auth.\n",
    "\n",
    "# ===============================================================\n",
    "# Save variables to Jupiter's temp storage so we can access it even if the kernel restarts.\n",
    "%store symlink_to_notebooks model_storage_dir repo_storage_dir activate_xformers link_novelai_anime_vae download_scripts activate_deepdanbooru activate_medvram disable_pickle_check gradio_port gradio_auth"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clone the central repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sBbcB4vwj_jm",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "%store -r symlink_to_notebooks model_storage_dir repo_storage_dir\n",
    "%cd /notebooks/\n",
    "\n",
    "def delete_broken_symlinks(path):\n",
    "    # make sure to pass this function a path without a trailing slash\n",
    "    for file in os.listdir(path):\n",
    "        if os.path.islink(f'{path}/{file}') and not os.path.exists(os.readlink(f'{path}/{file}')):\n",
    "            print(f'Symlink broken, removing: {file}')\n",
    "            os.unlink(f'{path}/{file}')\n",
    "\n",
    "def update_repo_if_not_exists(path, repo_clone_url, pre=None):\n",
    "    if pre is not None:\n",
    "        pre()    \n",
    "    if not os.path.exists(path):\n",
    "        !git clone \"{repo_clone_url}\" \"{path}\"\n",
    "    else:\n",
    "        print(f'{repo_clone_url.split(\"/\")[-1]} already downloaded, updating...')\n",
    "        !cd \"{path}\" && git pull # no % so we don't interfere with the main process\n",
    "\n",
    "def init_free():\n",
    "    if (symlink_to_notebooks and repo_storage_dir != '/notebooks'):\n",
    "        delete_broken_symlinks('/notebooks/') # remove broken symlinks since it might have been installed in a non-persistent directory\n",
    "        if not os.path.exists(repo_storage_dir):\n",
    "            !mkdir -p \"{repo_storage_dir}\"\n",
    "            !ln -s \"{repo_storage_dir}\" /notebooks/\n",
    "            !ls -la /notebooks/stable-diffusion\n",
    "update_repo_if_not_exists(f'{repo_storage_dir}/stable-diffusion-webui', 'https://github.com/AUTOMATIC1111/stable-diffusion-webui', init_free)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C68TUpkq0nj_",
    "tags": []
   },
   "source": [
    "## Install requirements and download repositories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SaAJk33ppFw1",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r symlink_to_notebooks model_storage_dir repo_storage_dir activate_xformers download_scripts activate_deepdanbooru\n",
    "%cd \"{repo_storage_dir}/stable-diffusion-webui\"\n",
    "import os\n",
    "\n",
    "# Import launch.py which will automatically run the install script but not launch the WebUI.\n",
    "# They require a few specific external git repo commits so we have to do it their way. \n",
    "import launch\n",
    "launch.prepare_enviroment()\n",
    "\n",
    "# The installer isn't installing deepdanbooru right now so we'll do it manually\n",
    "if activate_deepdanbooru:\n",
    "    !pip install \"git+https://github.com/KichangKim/DeepDanbooru.git@edf73df4cdaeea2cf00e9ac08bd8a9026b7a7b26#egg=deepdanbooru[tensorflow]\" # tensorflow==2.10.0 tensorflow-io==0.27.0 flatbuffers==1.12\n",
    "\n",
    "# latent-diffusion is a requirement but launch.py isn't downloading it so we'll do it manually.\n",
    "if not os.path.exists(f'{repo_storage_dir}/stable-diffusion-webui/repositories/latent-diffusion'):\n",
    "    !git clone https://github.com/crowsonkb/k-diffusion.git \"{repo_storage_dir}/stable-diffusion-webui/repositories/k-diffusion\"\n",
    "    !git clone https://github.com/Hafiidz/latent-diffusion.git \"{repo_storage_dir}/stable-diffusion-webui/repositories/latent-diffusion\"\n",
    "\n",
    "# Download popular custom scripts. This is basically remote code execution so be careful.\n",
    "# See https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Custom-Scripts\n",
    "if download_scripts:\n",
    "    !pip install requests\n",
    "    import shutil\n",
    "    import requests\n",
    "    !pip install moviepy==1.0.3\n",
    "    !apt update\n",
    "    !apt install -y potrace python3-tk\n",
    "\n",
    "    def download_file_dir(url, output_dir):\n",
    "        # output_dir must have a trailing slash\n",
    "        local_filename = url.split('/')[-1]\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(f'{output_dir}{local_filename}', 'wb') as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "        return local_filename\n",
    "    def do_script_download(scripts_list, domain, path):\n",
    "        for item in scripts_list:\n",
    "            download_file_dir(f'https://{domain}/{item}', path)\n",
    "            print(f'{item.split(\"/\")[-1]} downloaded...')\n",
    "\n",
    "    do_script_download([\n",
    "        'GRMrGecko/stable-diffusion-webui-automatic/advanced_matrix/scripts/advanced_prompt_matrix.py',\n",
    "        'dfaker/stable-diffusion-webui-cv2-external-masking-script/main/external_masking.py',\n",
    "        'memes-forever/Stable-diffusion-webui-video/main/videos.py',\n",
    "        'yownas/seed_travel/main/scripts/seed_travel.py',\n",
    "        'Animator-Anon/Animator/main/animation.py',\n",
    "        'Filarius/stable-diffusion-webui/master/scripts/vid2vid.py',\n",
    "        'GeorgLegato/Txt2Vectorgraphics/main/txt2vectorgfx.py',\n",
    "        'yownas/shift-attention/main/scripts/shift_attention.py',\n",
    "        'DiceOwl/StableDiffusionStuff/main/loopback_superimpose.py',\n",
    "        'Engineer-of-Stuff/stable-diffusion-paperspace/main/lfs/save_steps.py',\n",
    "        'Pfaeff/sd-web-ui-scripts/main/moisaic.py'\n",
    "    ], 'raw.githubusercontent.com', f'{repo_storage_dir}/stable-diffusion-webui/scripts/')\n",
    "\n",
    "    do_script_download([\n",
    "        'dfaker/f88aa62e3a14b559fe4e5f6b345db664/raw/791dabfa0ab26399aa2635bcbc1cf6267aa4ffc2/alternate_sampler_noise_schedules.py',\n",
    "        'camenduru/9ec5f8141db9902e375967e93250860f/raw/c1a03eb447548adbef1858c0e69d3567a390d2f4/run_n_times.py'\n",
    "    ], 'gist.githubusercontent.com', f'{repo_storage_dir}/stable-diffusion-webui/scripts/')\n",
    "\n",
    "    # Download and set up txt2img2img\n",
    "    update_repo_if_not_exists(f'{repo_storage_dir}/stable-diffusion-webui/txt2img2img_root', 'https://github.com/ThereforeGames/txt2img2img.git')\n",
    "    !cp -r \"{repo_storage_dir}/stable-diffusion-webui/txt2img2img_root/scripts\" \"{repo_storage_dir}/stable-diffusion-webui\"\n",
    "    !cp -r \"{repo_storage_dir}/stable-diffusion-webui/txt2img2img_root/txt2img2img\" \"{repo_storage_dir}/stable-diffusion-webui\"\n",
    "    !cp -r \"{repo_storage_dir}/stable-diffusion-webui/txt2img2img_root/venv\" \"{repo_storage_dir}/stable-diffusion-webui\"\n",
    "\n",
    "    # Download and set up txt2mask\n",
    "    update_repo_if_not_exists(f'{repo_storage_dir}/stable-diffusion-webui/txt2mask', 'https://github.com/ThereforeGames/txt2mask.git')\n",
    "    !echo \"Copying txt2mask...\"\n",
    "    !cp -r \"{repo_storage_dir}/stable-diffusion-webui/txt2mask/repositories/clipseg\" \"{repo_storage_dir}/stable-diffusion-webui/repositories\"\n",
    "    !cp -r \"{repo_storage_dir}/stable-diffusion-webui/txt2mask/scripts/\" \"{repo_storage_dir}/stable-diffusion-webui/\"\n",
    "\n",
    "    # Install the dynamic-prompts/wildcard script\n",
    "    !git clone https://github.com/adieyal/sd-dynamic-prompting/ extensions/dynamic-prompts\n",
    "\n",
    "if activate_xformers:\n",
    "    print('Installing xformers...')\n",
    "    import subprocess\n",
    "    def download_release(url):\n",
    "        binary = 'xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl' # have to save the binary as a specific name that pip likes\n",
    "        tmp_dir = subprocess.check_output(['mktemp', '-d']).decode('ascii').strip('\\n')\n",
    "        !wget \"{url}\" -O \"{tmp_dir}/{binary}\"\n",
    "        return os.path.join(tmp_dir, binary)\n",
    "\n",
    "    # Set up pip packages\n",
    "    !pip uninstall -y torch  torchvision torchaudio # Remove existing pytorch install.\n",
    "    !pip install torch torchvision torchaudio --extra-index-url https://download.pytorch.org/whl/cu113 # Install pytorch for cuda 11.3\n",
    "    s = subprocess.getoutput('nvidia-smi')\n",
    "    if 'A4000' in s:\n",
    "        xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A4000-Oct-28-2022/a4000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "    elif 'A5000' in s:\n",
    "        xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A5000-Nov-1-2022/a5000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "    elif 'A6000' in s:\n",
    "        xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A6000-Nov-1-2022/a6000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "    elif 'P5000' in s:\n",
    "        xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/P5000-Nov-1-2022/p5000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "    elif 'RTX 4000' in s:\n",
    "        xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/RTX-4000-Nov-1-2022/rtx4000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "    elif 'RTX 5000' in s:\n",
    "        xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/RTX-5000-Nov-1-2022/rtx5000-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "    elif 'A100' in s:\n",
    "        xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A100-Nov-1-2022/a100-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "    elif 'M4000' in s:\n",
    "        print('xformers for M4000 hasn\\'t been built yet.')\n",
    "        # xformers_whl = download_release('https://github.com/Cyberes/xformers-compiled/releases/download/A100-Nov-1-2022/a100-xformers-0.0.14.dev0-cp39-cp39-linux_x86_64.whl')\n",
    "    else:\n",
    "        print('GPU not matched to xformers binary so a one-size-fits-all binary was installed. If you have any issues, please build xformers using the Tools block below.')\n",
    "        xformers_whl = download_release('https://raw.githubusercontent.com/Cyberes/xformers-compiled/main/various/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl')\n",
    "    !pip install --force-reinstall \"{xformers_whl}\"\n",
    "\n",
    "# Make sure your models storage directory exists\n",
    "!mkdir -p \"{model_storage_dir}/hypernetworks\"\n",
    "!mkdir -p \"{repo_storage_dir}/stable-diffusion-webui/models/hypernetworks\"\n",
    "\n",
    "# Link the output folders to /notebooks/outputs\n",
    "!mkdir -p \"{repo_storage_dir}/stable-diffusion-webui/log/images\"\n",
    "!mkdir -p \"{repo_storage_dir}/stable-diffusion-webui/outputs\"\n",
    "!ln -s \"{repo_storage_dir}/stable-diffusion-webui/outputs\" /notebooks/\n",
    "!ln -s \"{repo_storage_dir}/stable-diffusion-webui/log\" \"{repo_storage_dir}/stable-diffusion-webui/outputs\"\n",
    "\n",
    "!echo -e \"\\n===================================\\nDone! If you're seeing this the process has exited successfully.\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Clean up and restart the kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r symlink_to_notebooks model_storage_dir repo_storage_dir\n",
    "\n",
    "# Get some storage back\n",
    "!pip cache purge\n",
    "!cd \"{model_storage_dir}\" && rm *.aria2\n",
    "!apt remove --purge -y aria2 p7zip-full\n",
    "!apt autoremove --purge -y\n",
    "!apt clean\n",
    "\n",
    "# Restart the kernel\n",
    "import os\n",
    "os.kill(os.getpid(), 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Link the models directory\n",
    "\n",
    "Create symlinks. The file will be stored in the models storage directory and linked to where the WebUI expects the files to be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "def delete_broken_symlinks(dir):\n",
    "    deleted = False\n",
    "    for file in os.listdir(dir):\n",
    "        path = f'{dir}/{file}'\n",
    "        if os.path.islink(path) and not os.path.exists(os.readlink(path)):\n",
    "            print(f'Symlink broken, removing: {file}')\n",
    "            os.unlink(path)\n",
    "            deleted = True\n",
    "    if deleted:\n",
    "        print('')\n",
    "    \n",
    "def symlink_models(source_dir, filetype, destination_dir):\n",
    "    # don't pass directory paths with trailing slash\n",
    "    if not os.path.isdir(source_dir):\n",
    "        print('Not a directory:', source_dir)\n",
    "        return\n",
    "    for file in os.listdir(source_dir):\n",
    "        if file.endswith(filetype):\n",
    "            path = f'{destination_dir}/{file}'\n",
    "            if not os.path.exists(path):\n",
    "                print(f'New model: {file}')\n",
    "                !ln -s \"{source_dir}/{file}\" \"{destination_dir}/{file}\"\n",
    "            !ls -la --block-size=GB \"{destination_dir}/{file}\"\n",
    "\n",
    "# Check for broken symlinks and remove them\n",
    "delete_broken_symlinks(f'{repo_storage_dir}/stable-diffusion-webui/models/Stable-diffusion')\n",
    "delete_broken_symlinks(f'{repo_storage_dir}/stable-diffusion-webui/models/hypernetworks')\n",
    "\n",
    "# Link models\n",
    "symlink_models(model_storage_dir, 'ckpt', f'{repo_storage_dir}/stable-diffusion-webui/models/Stable-diffusion')\n",
    "\n",
    "# Link models one level recursive\n",
    "# You can organize your models in your model storage dir into sub-folders.\n",
    "for file in os.listdir(model_storage_dir):\n",
    "    if os.path.isdir(os.path.join(model_storage_dir, file)) and file != 'hypernetworks':\n",
    "        symlink_models(os.path.join(model_storage_dir, file), 'ckpt', f'{repo_storage_dir}/stable-diffusion-webui/models/Stable-diffusion')\n",
    "\n",
    "# Link config yaml files\n",
    "symlink_models(model_storage_dir, 'yaml', f'{repo_storage_dir}/stable-diffusion-webui/models/Stable-diffusion')\n",
    "\n",
    "# Link hypernetworks\n",
    "symlink_models(f'{model_storage_dir}/hypernetworks', 'pt', f'{repo_storage_dir}/stable-diffusion-webui/models/hypernetworks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Update Dreambooth & pip install requirements\n",
    "!cd /notebooks/stable-diffusion-webui/extensions/sd_dreambooth_extension/\n",
    "!git pull\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xt8lbdmC04ox"
   },
   "source": [
    "# Launch the WebUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "R-xAdMA5wxXd",
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store -r model_storage_dir repo_storage_dir activate_xformers activate_deepdanbooru activate_medvram disable_pickle_check gradio_port gradio_auth\n",
    "%cd \"{repo_storage_dir}/stable-diffusion-webui\"\n",
    "\n",
    "# Enable optional args automatically based on settings\n",
    "x_arg = '--xformers' if activate_xformers else ''\n",
    "dd_arg = '--deepdanbooru' if activate_deepdanbooru else ''\n",
    "mvram_arg = '--medvram' if activate_medvram else ''\n",
    "pickled = '--disable-safe-unpickle' if disable_pickle_check else ''\n",
    "port = f'--port {gradio_port}' if gradio_port else '--share'\n",
    "auth = f'--gradio-auth {gradio_auth} --enable-insecure-extension-access' if gradio_auth else '--enable-insecure-extension-access'\n",
    "\n",
    "# Launch args go below:\n",
    "!python webui.py {x_arg} {dd_arg} {mvram_arg} {pickled} {port} {auth} --gradio-debug"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
